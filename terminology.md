1. Large Language Model

   A neural netwrok that is trained to predict the next term of an input sequence.

2. Tokenization

   Input text is broken into texts.

3. Vectors/Vectorization

   All input tokens for LLM are converted into vectors. Vectors encapsulate the meaning of that words.

4. Attention Mechanism

   Adding contextual meaning to the ambiguous vectors.

   For e.g. - Tasty apple.
               Apples's revenue.

   Same word but different meaning.

5. 
